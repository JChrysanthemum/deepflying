{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6CSZcMmU49c",
        "colab_type": "text"
      },
      "source": [
        "# 深度卷积对抗生成网络 ( 英语：Deep Convolution Generative Adversial Network，简称 ： DCGAN)\n",
        "\n",
        "<br></br>\n",
        "\n",
        " * [在 Google Colab 运行](https://colab.research.google.com/github/dslab-deepflying/deepflying/blob/master/InnoCamp/GANS/dcgan.ipynb)\n",
        " * [浏览 GitHub 源码 ](https://github.com/JChrysanthemum/deepflying/blob/master/InnoCamp/GANS/dcgan.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVpQ8qF6dkir",
        "colab_type": "text"
      },
      "source": [
        "## 概述\n",
        "\n",
        "<br>\n",
        "\n",
        "生成对抗网络（英语：Generative Adversarial Network，简称GAN）是非监督式学习的一种方法，通过让两个神经网络相互博弈的方式进行学习。该方法由[伊恩·古德费洛等人](https://arxiv.org/abs/1406.2661)于2014年提出。\n",
        "\n",
        "<br>\n",
        "\n",
        "判别网络的输入则为真实样本或生成网络的输出，其目的是将生成网络的输出从真实样本中尽可能分辨出来。而生成网络则要尽可能地欺骗判别网络。两个网络相互对抗、不断调整参数，最终目的是使判别网络无法判断生成网络的输出结果是否真实。\n",
        "\n",
        "<br>\n",
        "\n",
        "  生成对抗网络常用于生成以假乱真的图片。Alec Radford等人于2015年又提出了一种结合 CNN（卷积神经网络） 与 GAN 结合的机器学习的模型结构，[深度卷积对抗网络](https://arxiv.org/abs/1511.06434)(英语：Deep Convolutional Generative Adversarial Networks，简称DCGAN)。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwhl2eEqnP1-",
        "colab_type": "text"
      },
      "source": [
        "##  环境搭建"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hUpmPh8g9Qb",
        "colab_type": "text"
      },
      "source": [
        "###  所需包的导入\n",
        "\n",
        "<br>\n",
        "\n",
        "包（英文：package）是 python 中对一系列方法数据的封装，有面向对象编程（英文：Obect Oriented Coding，简称 OO）经验的同学来说并不陌生。对于没有OO基础的同学来说，包 可以简单的；理解为一种类似 “工具箱” 的概念。\n",
        "\n",
        "<br>\n",
        "\n",
        "我们本次实验使用的核心的包是[TensorFlow](https://www.tensorflow.org/?hl=zh_cn) ，谷歌公司的机器学习框架，也是当今世界上应用最广，发展最迅速的机器学习框架。[Keras](https://keras.io/zh/)是基于TensorFlow框架设计的高层抽象机器学习包。它使得我们能够略过数据操作中的张量操作以及计算图的编写运行等相对底层的操作，通过简单的 序贯模型 和 函数模型 快速搭建需要的机器学习模型。\n",
        "\n",
        "<br>\n",
        "\n",
        "其他包：<br>\n",
        "1）matplotlib ， python用于图像表格绘制的包<br>\n",
        "2）numpy ，python的数据运算工具包<br>\n",
        "3）pandas，python用于数据文件操作工具包<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMFyRnSYizyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import sys,os\n",
        "import numpy as np\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2LkljNjr7U0",
        "colab_type": "text"
      },
      "source": [
        "**注意：\n",
        "<br>由于Google Colab 不支持TensorFlow 2.0 ，本代码使用1.13版本\n",
        "<br>最新的 TensorFlow2.0 版本 相较于此版本代码有以下改动**<br>\n",
        "<br>1）keras包不必单独导入，可从TensorFlow直接导入。例如：<br>\n",
        "```\n",
        "    import keras                      // 旧方法\n",
        "\n",
        "    import tensorflow.keras           // 方法一\n",
        "\n",
        "    import tensorflow as tf           // 方法二\n",
        "    from tf.keras import *          \n",
        "\n",
        "```\n",
        "\n",
        "<br>2）keras 旧版本繁杂包管理更新。例如：\n",
        "```\n",
        "    //旧版\n",
        "    from keras.layers.advanced_activations import LeakyReLU\n",
        "    from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "    \n",
        "    //新版\n",
        "     from tensorflow.keras.layers import LeakyReLU\n",
        "     from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODVwUKq_jcpI",
        "colab_type": "text"
      },
      "source": [
        "### 所需文件下载以及解压\n",
        "\n",
        "[FashionMNIST](https://www.kaggle.com/zalando-research/fashionmnist)是德国Zalando公司的开源数据，分别有T恤、POLO衫、短裤、裙子、高跟鞋等多种服饰数据，每项数据为28X28的灰度图。\n",
        "\n",
        "本次实验所需的数据我已经为大家进行了了分开整理，方便大家使用。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Jv0sxNWuU49h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('GAN/data'):\n",
        "    os.makedirs('GAN/data')  \n",
        "!wget https://github.com/JChrysanthemum/deepflying/raw/master/InnoCamp/GANS/data/data.zip -O GAN/data/data.zip\n",
        "!unzip -o GAN/data/data.zip -d GAN/data/\n",
        "\n",
        "if not os.path.exists('GAN/models'):\n",
        "    os.makedirs('GAN/models')\n",
        "    \n",
        "if not os.path.exists('GAN/images'):\n",
        "    os.makedirs('GAN/images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSsf8zHKv4Qd",
        "colab_type": "text"
      },
      "source": [
        "## 代码编写\n",
        "\n",
        "接下来，我们将一步一步组建深度卷积对抗生成网络模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRxNdc0hwMsm",
        "colab_type": "text"
      },
      "source": [
        "### 超参数定义\n",
        "\n",
        "超参数是决定整个AI模型训练结果的 全局参数。在开头设置方便大家随时调整观察不同的结果。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nXjfs7KU49z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_ROWS = 28                           # 图片的行数，不用修改\n",
        "IMG_COLS = 28                           # 图片的列数，不用修改\n",
        "IMG_DATA_PATH = 'GAN/data/'             # 图片的路径，不用修改\n",
        "\n",
        "#@markdown 参数修改\n",
        "#@markdown ---\n",
        "#@markdown <br>\n",
        "# 训练数据的名称，可以自行修改\n",
        "\n",
        "#@markdown 训练数据名（默认 tee ）：\n",
        "data_name = 'tee'  #@param ['tee','ankle_boot', 'bag', 'coat', 'dress','pullover','sandal','shirt','sneaker','trouser']\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "ankle_boot  ---------  高跟鞋\n",
        "\n",
        "bag  ----------------  包\n",
        "\n",
        "coat  ---------------  外套\n",
        "\n",
        "dress  --------------  裙子\n",
        "\n",
        "pullover  -----------  套头衫\n",
        "\n",
        "sandal  -------------  凉鞋\n",
        "\n",
        "shirt  --------------  衬衫\n",
        "\n",
        "sneaker  ------------  运动鞋\n",
        "\n",
        "tee  ----------------  T恤\n",
        "\n",
        "trouser  ------------  裤子\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# 训练的批次数，在不考虑过拟合的情况下越大越好\n",
        "#@markdown 训练批次 （默认 100 ）： \n",
        "EPOCHS = 3100 #@param {type:\"slider\", min:0, max:7000, step:100}\n",
        "\n",
        "# 训练的批次大小，每次迭代需要的数据量，在资源足够下越大越好（越大越慢）\n",
        "#@markdown 训练批次大小 （默认 2 ）：\n",
        "BATCH_SIZE = 2 #@param [2,4,8,16,32]\n",
        "\n",
        "# 保存图片的间隔数\n",
        "#@markdown 图片保存和显示间隔 （默认 5 ）：\n",
        "SAVE_INTERVAL = 5 #@param {type:\"slider\", min:0, max:2000, step:5}\n",
        "\n",
        "#@markdown ---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HqaesXNy7c1",
        "colab_type": "text"
      },
      "source": [
        "### 网络定义"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXlZJck24xru",
        "colab_type": "text"
      },
      "source": [
        "#### 定义构造函数 （初始化函数）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIlVz6Zuy6Hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def __init__(self):\n",
        "    # Input shape\n",
        "    self.img_rows = IMG_ROWS\n",
        "    self.img_cols = IMG_COLS\n",
        "    self.channels = 1\n",
        "    self.img_shape = (IMG_ROWS, IMG_COLS, self.channels)\n",
        "    self.latent_dim = 100\n",
        "\n",
        "    optimizer = Adam(0.0002, 0.5)\n",
        "\n",
        "    # Build and compile the discriminator\n",
        "    self.discriminator = self.build_discriminator()\n",
        "    self.discriminator.compile(loss='binary_crossentropy',\n",
        "        optimizer=optimizer,\n",
        "        metrics=['accuracy'])\n",
        "\n",
        "    # Build the generator\n",
        "    self.generator = self.build_generator()\n",
        "\n",
        "    # The generator takes noise as input and generates imgs\n",
        "    z = Input(shape=(self.latent_dim,))\n",
        "    img = self.generator(z)\n",
        "\n",
        "    # For the combined model we will only train the generator\n",
        "    self.discriminator.trainable = False\n",
        "\n",
        "    # The discriminator takes generated images as input and determines validity\n",
        "    valid = self.discriminator(img)\n",
        "\n",
        "    # The combined model  (stacked generator and discriminator)\n",
        "    # Trains the generator to fool the discriminator\n",
        "    self.combined = Model(z, valid)\n",
        "    self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfVllhLo43Pm",
        "colab_type": "text"
      },
      "source": [
        "####  定义构造生成器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hzMd9EH12he",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(self):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
        "    model.add(Reshape((7, 7, 128)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "\n",
        "    # model.summary()\n",
        "\n",
        "    noise = Input(shape=(self.latent_dim,))\n",
        "    img = model(noise)\n",
        "\n",
        "    return Model(noise, img)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y4knA9-495t",
        "colab_type": "text"
      },
      "source": [
        "#### 定义构造判别器"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeZ54SGQ17Z2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(self):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # model.summary()\n",
        "\n",
        "    img = Input(shape=self.img_shape)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LIGyGxY5Co9",
        "colab_type": "text"
      },
      "source": [
        "定义训练方法和参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgePG8qB39cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(self, epochs, batch_size=128, save_interval=50):\n",
        "\n",
        "    # Load the dataset\n",
        "    te = pd.read_csv(IMG_DATA_PATH + data_name + '.csv', header=None)\n",
        "    X_train = []\n",
        "\n",
        "    for i in range(1, len(te)):\n",
        "        img = np.uint8(np.array(te.iloc[i]).reshape(28, 28))\n",
        "        X_train.append(img)\n",
        "\n",
        "    X_train = np.array(X_train)\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        # Select a random half of images\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        imgs = X_train[idx]\n",
        "\n",
        "        # Sample noise and generate a batch of new images\n",
        "        noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
        "        gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator (real classified as ones and generated as zeros)\n",
        "        d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
        "        d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Generator\n",
        "        # ---------------------\n",
        "\n",
        "        # Train the generator (wants discriminator to mistake images as real)\n",
        "        g_loss = self.combined.train_on_batch(noise, valid)\n",
        "\n",
        "        # Plot the progress\n",
        "        sys.stdout.write(\n",
        "            \"\\r%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100 * d_loss[1], g_loss))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        # If at save interval => save generated image samples\n",
        "        if epoch % save_interval == 0:\n",
        "            self.save_imgs(epoch)\n",
        "    self.generator.save('GAN/models/dcgan_G_%s_%d.h5' % (data_name, epochs))\n",
        "    self.discriminator.save('GAN/models/dcgan_D_%s_%d.h5' % (data_name, epochs))\n",
        "    print('\\n')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pUK75jr5MUO",
        "colab_type": "text"
      },
      "source": [
        "#### 定义保存和显示图片的函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42nyU_rd3-xO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def save_imgs(self, epoch):\n",
        "    r, c = 5, 5\n",
        "    noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
        "    gen_imgs = self.generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    fig_name = \"GAN/images/dcgan_%s_%d.png\" % (data_name, epoch)\n",
        "    if os.path.exists(sys.path[0] + \"/\" + fig_name):\n",
        "        os.remove(sys.path[0] + \"/\" + fig_name)\n",
        "    fig.savefig(fig_name)\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajbm9qvz5S2O",
        "colab_type": "text"
      },
      "source": [
        "#### 构造封装DCGAN类以便使用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwnz7j1j4Zum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DCGAN():\n",
        "  pass\n",
        "\n",
        "DCGAN.__init__ = __init__\n",
        "DCGAN.build_generator = build_generator\n",
        "DCGAN.build_discriminator = build_discriminator\n",
        "DCGAN.train = train\n",
        "DCGAN.save_imgs = save_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1qg26jX5fRk",
        "colab_type": "text"
      },
      "source": [
        "## 开始训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvSxuHpO5i2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "  dcgan = DCGAN()\n",
        "  dcgan.train(epochs=EPOCHS, batch_size=BATCH_SIZE, save_interval=SAVE_INTERVAL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}